{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e91244a-3b94-471a-a5de-fc8d931df16a",
   "metadata": {},
   "source": [
    "## Refer to https://docs.llamaindex.ai/en/stable/getting_started/starter_example_local/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3616ed-475d-49c5-b0ad-db8200e77491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b92d8b16-b4da-4310-b899-2a0d5f834364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enalbe 780M with ROCm\n",
    "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '11.0.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caad9c78-c4a6-4610-afe8-48348035e6e7",
   "metadata": {},
   "source": [
    "print(os.environ['HSA_OVERRIDE_GFX_VERSION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e7120a-8bc1-4c70-b61c-2ab6c3d1599b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c78f58e-ab6d-41b6-b80b-a91918397e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+rocm6.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e28c16f-2653-4d67-ac89-e72c210a83de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: AMD Radeon Graphics\n",
      "GPU properties: _CudaDeviceProperties(name='AMD Radeon Graphics', major=11, minor=0, gcnArchName='gfx1100', total_memory=16384MB, multi_processor_count=6)\n"
     ]
    }
   ],
   "source": [
    "# Query GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    print('Using GPU:', torch.cuda.get_device_name(0))\n",
    "    print('GPU properties:', torch.cuda.get_device_properties(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "351352b4-e0e1-4a37-b5b3-7cfbc3ba17c3",
   "metadata": {},
   "source": [
    "%pip install llama-index\n",
    "%pip install llama-index-llms-ollama\n",
    "%pip install llama-index-embeddings-ollama\n",
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e99b042-d0d5-4809-bc52-a5a3b0b1da21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igpu/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1931a4cc-4f0d-42fd-a7b8-68227a9f91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set embedding model\n",
    "#emb_fn=\"mxbai-embed-large\"\n",
    "emb_fn=\"nomic-embed-text\"\n",
    "\n",
    "#Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "Settings.embed_model = OllamaEmbedding(model_name=emb_fn)\n",
    "\n",
    "\n",
    "# Set ollama model\n",
    "Settings.llm = Ollama(model=\"tinyllama\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6de965-6f44-4e75-b4c9-664c455c5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "documents = SimpleDirectoryReader(input_files=[\"../data/FordUM.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "263515e8-6295-488b-ac2e-0606e143c186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 8f0fa2bb-a1f5-4d40-959c-912904587582\n",
      "Text: Storage S tate of Char ge You c an incr ease the b attery lif e\n",
      "by maint aining y our s tate of char ge bel ow 100%.  When y ou p ark\n",
      "y our v ehicl e for an extende d period of 30 da ys or mor e, we\n",
      "recommend y our b attery be a t an appr oxima tely 50% s tate of char\n",
      "ge. Storing y our v ehicl e's high v oltage battery at higher s tates\n",
      "of char ...\n"
     ]
    }
   ],
   "source": [
    "print(documents[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "741d2124-3812-4ba4-bc80-67411bf33d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize client and save data\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db/CUM_en_db\")\n",
    "# create collection\n",
    "chroma_collection = db.get_or_create_collection(\"CUM_en_db\")\n",
    "\n",
    "# assign chroma as the vector_store to the context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bb50a-a21b-4078-a540-43c714567014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vector index per-document\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    transformations=[SentenceSplitter(chunk_size=512, chunk_overlap=20)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8130646a-d736-4a49-8905-ed943f7fc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query your data\n",
    "query_engine = vector_index.as_query_engine(response_mode=\"refine\", similarity_top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc952e78-acc1-4434-ad96-9084bcc4cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Prompt for Car User Manual Q&A\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = (\n",
    "    \"You are proudct expert of car and very faimilay with car user manual and provide guide to the end user.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the information from multiple sources and not prior knowledge\\n\"\n",
    "    \"answer the question according to the care user manual with page number from the Index Table.\\n\"\n",
    "    \"if the question is not releate with car user manual, just say it is not releated with my knowledge base.\\n\"\n",
    "    \"if you don't know the answer, just say that I don't know.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"if the question is in chinese, please transclate chinese to english in advance\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
    ")\n",
    "\n",
    "template = (\n",
    "    \"The original query is as follows: {query_str}.\\n\"\n",
    "    \"We have provided an existing answer: {existing_answer}.\\n\"\n",
    "    \"We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\n\"\n",
    "    \"if the question is 'who are you' , just say I am Car User Manual Copilot.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Refined Answer: \"\n",
    ")\n",
    "\n",
    "\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:refine_template\": qa_template}\n",
    ")\n",
    "\n",
    "#prompts_dict = query_engine.get_prompts()\n",
    "#print(list(prompts_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34234116-6f78-4c7d-9830-d600743b42b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given text material, a refined answer meeting the specific requirements for answering the original query \"Who are you?\" can be as follows:\n",
      "\n",
      "- If the context is \"who are you\", simply state I am a user manual copilo. This provides detailed technical information about the Ext√©rior Lighting Control system in the trunk of the 2023 F-150 Lightning Electric, Cananada/United States, Edition 202206, Domestic Standard Automatic Transmission (SAT), and Edition DOT. This should provide more context for the original query and meet its specific requirements.\n"
     ]
    }
   ],
   "source": [
    "# Query Test 0\n",
    "response = query_engine.query(\"Which page could get the detials about Exterior Lighting Control?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c44b0693-1c90-4d42-8b5b-0fee3a508a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided in the given text, the query is \"What types of Booster Sets supported are available for this car model?\"\n",
      "\n",
      "The answer to this query would be based on the information provided in the page label and file path. The page label indicates that a specific Ford model, the UM (United States of America), was being discussed. The file path is \"../../data/FordUM.pdf\" which contains the Car User Manual Copilo t. It is evident from this information that the car model being discussed has access to phone app data for passeginger communication via hands-free calling and messaging, as well as vehicle control options (e.g., Drifting modes, idle mode, emergency calls). These options include automatic transmission (AT), traction control (TC), rear-view mirror (RVM), towing mode, emergency call, personal profile management (PPM), and automatic transmission (AT) is designed to prevent the wheel from spinning out of control during drift-control maneuvers.\n"
     ]
    }
   ],
   "source": [
    "# Q2\n",
    "response = query_engine.query(\"How may types of Booster Setats supported in this car?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bc008ff-96ad-43ef-a9cd-525e1d362afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To access the Intellegenit Beds switch in the user interface, navigate to the \"Switching The Intelegenit Beds\" button on the page of the Home Assistant app or the Google Assistant app, then select it from the options. If the user is already using pre-set emergency locations for their location and preferred resources, they may simply press the corresponding switch on their device to switch between those locations. To play music on the BlueTooth¬Æ system of the user's bed, navigate to the \"Play Music\" option in the app or Google Assistant app and select it from the options. The \"Preparing Your Vehicle for Storage\" section describes preparing your vehicle for storage after driving and includes recommendations for ensuring safety during storage, such as using an Extra Hand-Held Device and encouraging the use of voice-operated systems when operating while driving. For more information about programming a MyKeeper device, users can refer to the \"Programming\" section. The \"Conducting Extreme Cautious Operations While Driving\" section warns about the dangers of using electronic devices while driving and recommends safety measures, such as ensuring that a phone is off and using an Extra Hand-Held Device when operating.\n"
     ]
    }
   ],
   "source": [
    "# Q3\n",
    "response = query_engine.query(\"HOW DOES 911 ASSIST WORK?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d0eeeb8-d2ef-4480-8729-e44741c4bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In response to \"Who is the contact number for the Ford customer relationship center in China?\", the refined answer is:\n",
      "\n",
      "The contact number for the Ford customer relationship center in China can be accessed by calling 800.392.3673 or visiting their website at www.ford.com/Help. To access an account manager, visit www.ford.ca. The additional commands available to enable voice commands are listed on page 486. Voice commands can be used with various features, including setting preferred words, switching between phone and vehicle confirmation modes, switching between wake word options, viewing the commands help menu, and selecting a preferred mode for setting a preference or enabling voice commands.\n"
     ]
    }
   ],
   "source": [
    "# Q4\n",
    "response = query_engine.query(\"Give me the phone number of the customer relationship center in China\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15244250-3cd2-4b92-aa7e-c08ddb99aed6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! To answer the query regarding Ford F-150's massage seats, specific models with this feature may vary depending on your location and dealership. You can inquire about availability at the Ford website or contact the dealership to verify. The context of the original question is not particularly useful for answering it as it doesn't provide any additional information or details related to the product. In order to refine the existing answer, we can add more specificity and detail by referencing the available trim levels and models with massage seat availability. By doing so, we can provide a clearer picture of what options are currently available for this feature on various Ford F-150 models.\n"
     ]
    }
   ],
   "source": [
    "# Q5\n",
    "response = query_engine.query(\"Does Ford F-150 have massage seats?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccfbd7aa-2d8c-49d2-8746-39bfc9ec8441",
   "metadata": {},
   "source": [
    "vector_index.storage_context.persist(persist_dir=\"RAG_Demo_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae14b2-2d82-423a-8725-b0977cf8c3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
